---
layout: post
title: "The Declarative Computation Model: Notes on CTM Chapter 02"
published: false
---
# 

*This post is part of a series. Check the <a href="/">blog index</a> for the rest.*

### The Declarative Computation Model: Notes on _CTM_ Chapter 02

> "In our view, languages that scale to a significant level of complexity are successful in part because they model some essential aspects of how to construct complex programs. In this sense, these languages are not just arbitrary constructions of the human mind. We would therefore like to understand them in a scientific way, _i.e._, by explaining their behavior in terms of a simple underlying model. This is the deep motivation behind the kernel language approach." - _Section 2.1.2_

This chapter, the first of the chapters in "Section 1: General Computation Models," is an introduction to programming languages from the ground up - how the characters that compose our input are transformed and executed. Lexical analysis, parsing, grammars, semantics, abstract machines, garbage collection, and unification are all discussed, amongst other concepts. The kernel language approach is _demonstrated_, and the subject is the declarative computational model, a simple, compact language defined as "evaluating functions over partial data structures."



#### How To Define A Grammar

One of the nicer parts of this chapter is the treatment of _Extended Backus-Naur Form_ which is used throughout the book to define grammars. It is a very commonly used form, and has a concise explanation:

> "The EBNF notation distinguishes terminal symbols and nonterminal symbols. A terminal symbol is simply a token. A nonterminal symbol represents a sequence of tokens. The nonterminal is defined by a grammar rule, which shows how to expand it into tokens."

Here is an example from the book (rendered here using the awesome <a href="http://www.mathjax.org">MathJax</a>) of defining the grammar for a $digit$:

$$\<digit>::=0|1|2|3|4|5|6|7|8|9$$

It says that a digit, which is a nonterminal (notated with $<$ and $>$), represents one of the ten tokens separated by $|$, (or) symbols. To illustrate how simple rules can combine to form more complex ones, a rule for $int$ is shown, which relies on the previous definition of $digit$:

$$\<int\>::=\<digit\>\\{\<digit\>\\}$$

An $int$ is one $digit$, followed by one or more $digit$. The { and } mean 'anything contained within will occur zero or more times.' If you try some test cases, you will see that these are sound definitions.

You can use a simple procedure to read the grammars that appear throughout the book. Start with any nonterminal symbol ($\<int\>$ for example), and reading the rule from left to right, you will see a sequence of tokens that follow these rules:

* Each terminal symbol encountered is added to the sequence.
* For each nonterminal symbol, read its grammar rule and replace the nonterminal with the sequence of tokens that it expands into
* Each time there is a choice (with $|$), pick any of the alternatives

The trade-off in having as succinct a means of expressing the syntax of a language as EBNF provides is that it does not cover all of the rules of a practical programming language. EBNFs generate what are known as "context free grammars" because they assume a certain amount of context when asserting the correctness of some expressions in the language. Therefore the definition of the operation of most practical programming languages include a context free grammar in addition to a set of rules or conditions that must be satisfied before correct operation can be guaranteed.

#### Context, Syntax, and Ambiguity

The text deftly demonstrates how the formal semantics of a language cannot wholly express its behavior. There are other rules or contexts necessary to understand how code will operate. In addition to the conditions mentioned above, Context Free Grammars can be _ambiguous_ - several different parse trees can be generated from the same sequence of tokens. By adding rules for _precedence_ and _associativity_, we can avoid any ambiguities in expressions defined with operators. There is a table in Chapter 2 which describes these rules for all operations.

#### Language Semantics and the Kernel Language Approach

> "The semantics of a language defines what a program does when it executes."

The authors are interested in provided a practical means by which programmers can reason about programs that they create in a rigorous way without having to sacrifice the expressiveness of the languages that they choose to employ. The mechanism that allows us to be rigorous and expressive simultaneously is called the kernel language approach. This chapter serves to introduce the idea, and to demonstrate the concepts with the simplest kernel language, known as the _declarative kernel language_.

The _kernel language approach_ consists of two parts:

1. Define a kernel language, which is a very simple language that represents the essence of the desired functionality of the end user language.
2. Provide a translation scheme from the kernel language to a practical programming language.  Two means of extending a kernel language are provided: _linguistic abstraction_ and _syntactic sugar_.

_I wrote an article detailing more about the pedagogy of the book as it relates to the kernel language approach. <a href="http://michaelrbernste.in/2013/02/23/notes-on-teaching-with-the-kernel-language-approach.html">Check it out here</a>._

#### Translation

*Linguistic Abstraction* is the business

*Syntactic Sugar* is sweet


#### The Mechanics of the Declarative Language

* Declarative Variables
* Value Store
* Value Creation and Value Identifiers
* Partial Values
* Dataflow Variables


#### The Declarative Kernel Language

<center><img src="/images/declarative_kernel.png"></center>

* Syntax
* Values and Types
* Basic Types
* Records and Procedures
* Basic Operations
 

#### Kernel Language Semantics

* Simple Execution
* Procedures
* Static and Dynamic Scope
* Procedural Abstraction

#### The Abstract Machine

* Definitions
* Program Execution

> "A single transition in a computation is called a computation step. A computation step is atomic, i.e., there are no visible intermediate states. It is as if the step is done 'all at once.'"

The section on program execution demonstrates how the following code is executed by the abstract machine:

{% highlight ruby %}
local X in #<s> begin
  X = 1
  local X in #<s>1 begin
    X = 2
    { Browse X }
  end #<s>1 end
  { Browse X } # <s>2 begin/end
end #<s> end
{% endhighlight %}

The exercise is to read the above code, reason about it, and predict what the execution will look like. The `Browse` function displays the value passed to it. As we've already seen a discussion of scope, it should be clear that the interesting aspects of how this program execute relate to the semantics of the kernel language.

$$(ST, \sigma)(1)$$
$$([(\lt s \gt, \emptyset)], \emptyset)(2)$$
$$([(\lt s \gt_1  \lt s \gt_2,\\{X \rightarrow x\\})], \\{x = 1\\})(3)$$
$$([(\lt s \gt_1, \\{X \rightarrow x\\}),  (\lt s \gt_2,\\{X \rightarrow x\\})], \\{x = 1\\})(4)$$
$$([(X=2, \\{Browse \space X\\}, \\{X \rightarrow x'\\}),  (\lt s \gt_2,\\{X \rightarrow x\\})], \\{x', x = 1\\})(5)$$
$$([(\\{Browse \space X\\}, \\{X \rightarrow x'\\}),  (\\{Browse \space X\\}, \\{X \rightarrow x\\})], \\{x' = 2, x = 1\\})(6)$$

$(1)$ The execution state is represented by a stack of semantic statements $ST$ and a value store $\sigma$. A semantic statement is a pair $(\lt s \gt,E)$, where $\lt s \gt$ is a statement and $E$ is an environment - a mapping of variables to values stored in $\sigma$.

$(2)$ The initial execution state of our program in the abstract machine. $E$ has been substituted by $\lt s \gt$, a statement which represents the outermost $local$ statement in the program, and $\emptyset$, meaning there are not yet any mappings present. The value store has also been replaced with $\emptyset$ - it has no members.

$(3)$ The outermost $local$ statement and $X = 1$ are executed. There is a sequential composition $\lt s \gt_1\lt s \gt_2$ remaining, the environment reflects that $X$ refers to the store variable $x$, and one binding ($x=1$) is added to $\sigma$.

$(4)$ After executing the sequential composition we see that each statement ends up with its own environment; they are now on the execution stack. We will sequentially execute each statement next.

$(5)$ Executing $\lt s \gt_1$ binds a new variable $x'$ and calculates a new environment. This has a clear semantic specification; given an initial $E$ of $\\{X \rightarrow x\\}$, adding $\\{X \rightarrow x'\\}$ to it will yield $\\{X \rightarrow x'\\}$. The second mapping of $X$ overrides the first.

$(6)$ $\lt s \gt_2$ is a $Browse$ statment, and $X = 2$ is bound. From this we can tell that we will see $Browse$ run twice - the first will show 2, and the second will show 1.

This simple exercise highlights the scoping semantics of the declarative kernel language. 

#### Memory Management

* Memory Life Cycle
* Garbage Collection

#### From Kernel Language to Practical Language

* Syntax
* Expressions
* Functions
* Exceptions

#### Functional Languages and Unification
